{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Intel-Bildklassifizierung (CNN – Keras)\n\nHallo, ich hoffe, Sie haben einen schönen Tag.\n\nIn diesem Notizbuch werde ich den Prozess der Implementierung von CNN mit Keras ausprobieren, um Bilder zu klassifizieren.\n1. Zuerst importieren wir nützliche Pakete.\n1. Anschließend laden wir die Daten, bevor wir sie visualisieren und vorverarbeiten.\n1. Wir testen ein einfaches CNN-Modell und bewerten dann seine Leistung.\n1. Anschließend werden wir ein vorab trainiertes Modell verwenden, um auch dieser Herausforderung zu begegnen.**","metadata":{}},{"cell_type":"markdown","source":"# # Pakete importieren","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt             \nimport cv2                                 \nimport tensorflow as tf                \nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:26:54.910574Z","iopub.execute_input":"2023-07-16T14:26:54.910967Z","iopub.status.idle":"2023-07-16T14:26:54.919976Z","shell.execute_reply.started":"2023-07-16T14:26:54.910935Z","shell.execute_reply":"2023-07-16T14:26:54.918635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n\nnb_classes = len(class_names)\n\nIMAGE_SIZE = (150, 150)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:26:57.709226Z","iopub.execute_input":"2023-07-16T14:26:57.709660Z","iopub.status.idle":"2023-07-16T14:26:57.716562Z","shell.execute_reply.started":"2023-07-16T14:26:57.709628Z","shell.execute_reply":"2023-07-16T14:26:57.715214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Laden der Daten\nWir müssen eine Load_Data-Funktion schreiben, die die Bilder und Beschriftungen aus dem Ordner lädt.","metadata":{}},{"cell_type":"code","source":"def load_data():\n    \"\"\"\n        Load the data:\n            - 14,034 images to train the network.\n            - 3,000 images to evaluate how accurately the network learned to classify images.\n    \"\"\"\n    \n    datasets = ['/kaggle/input/intel-image-classification/seg_train/seg_train', '/kaggle/input/intel-image-classification/seg_test/seg_test']\n    output = []\n    \n    # Iterate through training and test sets\n    for dataset in datasets:\n        \n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            label = class_names_label[folder]\n            \n            # Iterate through each image in our folder\n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n                \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n                \n                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE) \n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:27:31.148629Z","iopub.execute_input":"2023-07-16T14:27:31.149039Z","iopub.status.idle":"2023-07-16T14:27:31.161003Z","shell.execute_reply.started":"2023-07-16T14:27:31.149006Z","shell.execute_reply":"2023-07-16T14:27:31.159344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_images, train_labels), (test_images, test_labels) = load_data()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:27:35.007423Z","iopub.execute_input":"2023-07-16T14:27:35.007888Z","iopub.status.idle":"2023-07-16T14:29:42.192001Z","shell.execute_reply.started":"2023-07-16T14:27:35.007854Z","shell.execute_reply":"2023-07-16T14:29:42.190668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images, train_labels = shuffle(train_images, train_labels, random_state=25)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:30:17.271023Z","iopub.execute_input":"2023-07-16T14:30:17.271538Z","iopub.status.idle":"2023-07-16T14:30:19.452050Z","shell.execute_reply.started":"2023-07-16T14:30:17.271496Z","shell.execute_reply":"2023-07-16T14:30:19.451034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lassen Sie uns den Datensatz untersuchen\nWir können uns fragen:\n* Wie viele Trainings- und Testbeispiele haben wir?\n* Wie groß sind die Bilder?\n* Wie groß ist der Anteil jeder beobachteten Kategorie?","metadata":{}},{"cell_type":"code","source":"n_train = train_labels.shape[0]\nn_test = test_labels.shape[0]\n\nprint (\"Number of training examples: {}\".format(n_train))\nprint (\"Number of testing examples: {}\".format(n_test))\nprint (\"Each image is of size: {}\".format(IMAGE_SIZE))","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:30:25.432307Z","iopub.execute_input":"2023-07-16T14:30:25.432748Z","iopub.status.idle":"2023-07-16T14:30:25.440734Z","shell.execute_reply.started":"2023-07-16T14:30:25.432714Z","shell.execute_reply":"2023-07-16T14:30:25.439240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n_, train_counts = np.unique(train_labels, return_counts=True)\n_, test_counts = np.unique(test_labels, return_counts=True)\npd.DataFrame({'train': train_counts,\n                    'test': test_counts}, \n             index=class_names\n            ).plot.bar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:30:50.890263Z","iopub.execute_input":"2023-07-16T14:30:50.890693Z","iopub.status.idle":"2023-07-16T14:30:51.290655Z","shell.execute_reply.started":"2023-07-16T14:30:50.890659Z","shell.execute_reply":"2023-07-16T14:30:51.289355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.pie(train_counts,\n        explode=(0, 0, 0, 0, 0, 0) , \n        labels=class_names,\n        autopct='%1.1f%%')\nplt.axis('equal')\nplt.title('Anteil jeder beobachteten Kategorie')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:31:30.177521Z","iopub.execute_input":"2023-07-16T14:31:30.177943Z","iopub.status.idle":"2023-07-16T14:31:30.391465Z","shell.execute_reply.started":"2023-07-16T14:31:30.177911Z","shell.execute_reply":"2023-07-16T14:31:30.389671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gute Praxis: Skalieren Sie die Daten","metadata":{}},{"cell_type":"code","source":"train_images = train_images / 255.0 \ntest_images = test_images / 255.0","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:32:51.878028Z","iopub.execute_input":"2023-07-16T14:32:51.878503Z","iopub.status.idle":"2023-07-16T14:32:53.529094Z","shell.execute_reply.started":"2023-07-16T14:32:51.878461Z","shell.execute_reply":"2023-07-16T14:32:53.527831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualisieren Sie die Daten\nWir können ein zufälliges Bild aus dem Trainingssatz anzeigen.","metadata":{}},{"cell_type":"code","source":"def display_random_image(class_names, images, labels):\n    \"\"\"\n        Display a random image from the images array and its correspond label from the labels array.\n    \"\"\"\n    \n    index = np.random.randint(images.shape[0])\n    plt.figure()\n    plt.imshow(images[index])\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:33:34.288319Z","iopub.execute_input":"2023-07-16T14:33:34.288798Z","iopub.status.idle":"2023-07-16T14:33:34.297836Z","shell.execute_reply.started":"2023-07-16T14:33:34.288755Z","shell.execute_reply":"2023-07-16T14:33:34.296228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_random_image(class_names, train_images, train_labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:33:50.064856Z","iopub.execute_input":"2023-07-16T14:33:50.065317Z","iopub.status.idle":"2023-07-16T14:33:50.329198Z","shell.execute_reply.started":"2023-07-16T14:33:50.065259Z","shell.execute_reply":"2023-07-16T14:33:50.327890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wir können die ersten 25 Bilder aus dem Trainingssatz auch direkt mit einer Schleife anzeigen, um eine bessere Ansicht zu erhalten","metadata":{}},{"cell_type":"code","source":"def display_examples(class_names, images, labels):\n    \"\"\"\n        Zeigen Sie 25 Bilder aus dem Bilder-Array mit den entsprechenden Beschriftungen an\n    \"\"\"\n    \n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Zeigen Sie 25 Bilder aus dem Bilder-Array mit den entsprechenden Beschriftungen an\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.binary)\n        plt.xlabel(class_names[labels[i]])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:35:45.832375Z","iopub.execute_input":"2023-07-16T14:35:45.832801Z","iopub.status.idle":"2023-07-16T14:35:45.841332Z","shell.execute_reply.started":"2023-07-16T14:35:45.832767Z","shell.execute_reply":"2023-07-16T14:35:45.840087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_examples(class_names, train_images, train_labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:35:48.618083Z","iopub.execute_input":"2023-07-16T14:35:48.618570Z","iopub.status.idle":"2023-07-16T14:35:50.540004Z","shell.execute_reply.started":"2023-07-16T14:35:48.618531Z","shell.execute_reply":"2023-07-16T14:35:50.538974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Anfänger: Einfache Modellerstellung\n\nSchritte sind:\n1. Bauen Sie das Modell,\n1. Kompilieren Sie das Modell.\n1. Trainieren / Anpassen der Daten an das Modell,\n1. Bewerten Sie das Modell anhand des Testsatzes.\n1. Führen Sie eine Fehleranalyse unseres Modells durch.\n\nWir können ein einfaches Modell erstellen, das aus verschiedenen Schichten besteht, wie zum Beispiel:\n* Conv2D: (32 Filter der Größe 3 x 3) Die Features werden aus dem Bild „extrahiert“.\n* MaxPooling2D: Die Bilder werden halbiert.\n* Flatten: Transformiert das Format der Bilder von einem 2D-Array in ein 1D-Array mit 150 150 3 Pixelwerten.\n* Relu: Wenn ein Wert x gegeben ist, wird max(x, 0) zurückgegeben.\n* Softmax: 6 Neuronen, Wahrscheinlichkeit, dass das Bild zu einer der Klassen gehört.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:36:49.216549Z","iopub.execute_input":"2023-07-16T14:36:49.216987Z","iopub.status.idle":"2023-07-16T14:36:49.507871Z","shell.execute_reply.started":"2023-07-16T14:36:49.216944Z","shell.execute_reply":"2023-07-16T14:36:49.506670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dann können wir es mit einigen Parametern kompilieren, wie zum Beispiel:\n* **Optimierer**: adam = RMSProp + Momentum.\nWas ist Momentum und RMSProp?\n* Momentum = berücksichtigt den Verlauf der Vergangenheit, um eine bessere Aktualisierung zu ermöglichen.\n* RMSProp = exponentiell gewichteter Durchschnitt der Quadrate vergangener Gradienten.\n* **Verlustfunktion**: Wir verwenden zur Klassifizierung eine spärliche kategoriale Kreuzentropie, jedes Bild gehört nur zu einer Klasse","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:37:42.089897Z","iopub.execute_input":"2023-07-16T14:37:42.090486Z","iopub.status.idle":"2023-07-16T14:37:42.118675Z","shell.execute_reply.started":"2023-07-16T14:37:42.090438Z","shell.execute_reply":"2023-07-16T14:37:42.117257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wir passen das Modell an die Daten aus dem Trainingssatz an. Das neuronale Netzwerk lernt das Muster selbst, um die einzelnen Kategorien zu unterscheiden.","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_images, train_labels, batch_size=128, epochs=20, validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:38:25.941630Z","iopub.execute_input":"2023-07-16T14:38:25.942036Z","iopub.status.idle":"2023-07-16T15:45:51.803901Z","shell.execute_reply.started":"2023-07-16T14:38:25.942004Z","shell.execute_reply":"2023-07-16T15:45:51.802510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_accuracy_loss(history):\n    \"\"\"\n        Plot the accuracy and the loss during the training of the nn.\n    \"\"\"\n    fig = plt.figure(figsize=(10,5))\n\n    # Plot accuracy\n    plt.subplot(221)\n    plt.plot(history.history['acc'],'bo--', label = \"acc\")\n    plt.plot(history.history['val_acc'], 'ro--', label = \"val_acc\")\n    plt.title(\"train_acc vs val_acc\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epochs\")\n    plt.legend()\n\n    # Plot loss function\n    plt.subplot(222)\n    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n    plt.title(\"train_loss vs val_loss\")\n    plt.ylabel(\"loss\")\n    plt.xlabel(\"epochs\")\n\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T15:46:24.363241Z","iopub.execute_input":"2023-07-16T15:46:24.364398Z","iopub.status.idle":"2023-07-16T15:46:24.373519Z","shell.execute_reply.started":"2023-07-16T15:46:24.364353Z","shell.execute_reply":"2023-07-16T15:46:24.372162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracy_loss(history)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T15:47:10.992379Z","iopub.execute_input":"2023-07-16T15:47:10.992808Z","iopub.status.idle":"2023-07-16T15:47:11.425997Z","shell.execute_reply.started":"2023-07-16T15:47:10.992774Z","shell.execute_reply":"2023-07-16T15:47:11.424493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We should evaluate the model performance on test set","metadata":{}},{"cell_type":"code","source":"test_loss = model.evaluate(test_images, test_labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T15:47:36.677077Z","iopub.execute_input":"2023-07-16T15:47:36.677465Z","iopub.status.idle":"2023-07-16T15:47:50.525909Z","shell.execute_reply.started":"2023-07-16T15:47:36.677430Z","shell.execute_reply":"2023-07-16T15:47:50.524849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that we achieve 0.76 accuracy on the testing test. We got a slight underfitting :(\n\nLet's see how the classifier is doing on random images.","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(test_images)     # Vector of probabilities\npred_labels = np.argmax(predictions, axis = 1) # We take the highest probability\n\ndisplay_random_image(class_names, test_images, pred_labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T15:48:24.802229Z","iopub.execute_input":"2023-07-16T15:48:24.802956Z","iopub.status.idle":"2023-07-16T15:48:39.282463Z","shell.execute_reply.started":"2023-07-16T15:48:24.802911Z","shell.execute_reply":"2023-07-16T15:48:39.281182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fehleranalyse\n\nWir können versuchen zu verstehen, bei welcher Art von Bildern der Klassifikator Probleme hat.","metadata":{}},{"cell_type":"code","source":"def print_mislabeled_images(class_names, test_images, test_labels, pred_labels):\n    \"\"\"\n        Print 25 examples of mislabeled images by the classifier, e.g when test_labels != pred_labels\n    \"\"\"\n    BOO = (test_labels == pred_labels)\n    mislabeled_indices = np.where(BOO == 0)\n    mislabeled_images = test_images[mislabeled_indices]\n    mislabeled_labels = pred_labels[mislabeled_indices]\n\n    title = \"Some examples of mislabeled images by the classifier:\"\n    display_examples(class_names,  mislabeled_images, mislabeled_labels)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-16T15:49:04.044452Z","iopub.execute_input":"2023-07-16T15:49:04.044827Z","iopub.status.idle":"2023-07-16T15:49:04.052680Z","shell.execute_reply.started":"2023-07-16T15:49:04.044797Z","shell.execute_reply":"2023-07-16T15:49:04.051272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_mislabeled_images(class_names, test_images, test_labels, pred_labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T15:49:08.465322Z","iopub.execute_input":"2023-07-16T15:49:08.465769Z","iopub.status.idle":"2023-07-16T15:49:10.524521Z","shell.execute_reply.started":"2023-07-16T15:49:08.465735Z","shell.execute_reply":"2023-07-16T15:49:10.523403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CM = confusion_matrix(test_labels, pred_labels)\nax = plt.axes()\nsn.heatmap(CM, annot=True, \n           annot_kws={\"size\": 10}, \n           xticklabels=class_names, \n           yticklabels=class_names, ax = ax)\nax.set_title('Confusion matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T15:49:19.289062Z","iopub.execute_input":"2023-07-16T15:49:19.289517Z","iopub.status.idle":"2023-07-16T15:49:19.836072Z","shell.execute_reply.started":"2023-07-16T15:49:19.289480Z","shell.execute_reply":"2023-07-16T15:49:19.834551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fazit: Der Klassifikator hat Probleme mit zwei Arten von Bildern.\nEs gibt Probleme mit Straßen und Gebäuden. Nun, es kann verständlich sein, da es Gebäude auf der Straße gibt.\nEs gibt auch Probleme mit dem Meer, dem Gletscher und den Bergen. Es fällt mir schwer, sie vollständig zu unterscheiden.\nEs kann jedoch Wälder sehr genau erkennen!","metadata":{}},{"cell_type":"markdown","source":"**Zwischenaktualisierung Januar 2020**\n\n* Merkmalsextraktion mit VGG16, trainiert auf ImageNet\n\n\n* Ensemble-Modelle neuronaler Netze mit den aus VGG extrahierten Merkmalen\n\nInspiriert von: https://machinelearningmastery.com/model-averaging-ensemble-for-deep-learning-neural-networks/\n\n* Feinabstimmung mit VGG16, trainiert auf ImageNet","metadata":{}},{"cell_type":"markdown","source":"# Merkmalsextraktion mit VGG ImageNet","metadata":{}},{"cell_type":"markdown","source":"Wir können Funktionen aus VGG16 extrahieren.","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\n\nmodel = VGG16(weights='imagenet', include_top=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T15:49:28.858203Z","iopub.execute_input":"2023-07-16T15:49:28.858691Z","iopub.status.idle":"2023-07-16T15:49:29.929637Z","shell.execute_reply.started":"2023-07-16T15:49:28.858653Z","shell.execute_reply":"2023-07-16T15:49:29.928460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Holen Sie sich die Funktionen direkt von VGG16","metadata":{}},{"cell_type":"code","source":"train_features = model.predict(train_images)\ntest_features = model.predict(test_images)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T15:49:35.092842Z","iopub.execute_input":"2023-07-16T15:49:35.093337Z","iopub.status.idle":"2023-07-16T16:24:23.887818Z","shell.execute_reply.started":"2023-07-16T15:49:35.093278Z","shell.execute_reply":"2023-07-16T16:24:23.886770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualisieren Sie die Funktionen durch PCA","metadata":{}},{"cell_type":"code","source":"n_train, x, y, z = train_features.shape\nn_test, x, y, z = test_features.shape\nnumFeatures = x * y * z","metadata":{"execution":{"iopub.status.busy":"2023-07-16T16:24:29.417828Z","iopub.execute_input":"2023-07-16T16:24:29.418307Z","iopub.status.idle":"2023-07-16T16:24:29.425109Z","shell.execute_reply.started":"2023-07-16T16:24:29.418255Z","shell.execute_reply":"2023-07-16T16:24:29.423563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import decomposition\n\npca = decomposition.PCA(n_components = 2)\n\nX = train_features.reshape((n_train, x*y*z))\npca.fit(X)\n\nC = pca.transform(X) # Darstellung von Personen in den neuen Achsen\nC1 = C[:,0]\nC2 = C[:,1]","metadata":{"execution":{"iopub.status.busy":"2023-07-16T16:24:33.615422Z","iopub.execute_input":"2023-07-16T16:24:33.615893Z","iopub.status.idle":"2023-07-16T16:24:38.515397Z","shell.execute_reply.started":"2023-07-16T16:24:33.615860Z","shell.execute_reply":"2023-07-16T16:24:38.513751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Figures\n\nplt.subplots(figsize=(10,10))\n\nfor i, class_name in enumerate(class_names):\n    plt.scatter(C1[train_labels == i][:1000], C2[train_labels == i][:1000], label = class_name, alpha=0.4)\nplt.legend()\nplt.title(\"PCA Projection\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T16:24:42.731828Z","iopub.execute_input":"2023-07-16T16:24:42.732301Z","iopub.status.idle":"2023-07-16T16:24:43.763252Z","shell.execute_reply.started":"2023-07-16T16:24:42.732247Z","shell.execute_reply":"2023-07-16T16:24:43.762216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dank dieser PCA können wir Cluster identifizieren. Die Cluster entsprechen mehr oder weniger den Beschriftungen.\n\nWir sehen, dass Gletscher- und Bergpunkte sehr nahe beieinander liegen, da VGG sie als sehr ähnlich ansieht.\n\nWir sehen, dass es keinen Unterschied zwischen Gebäude und Straße gibt.","metadata":{}},{"cell_type":"markdown","source":"## Training zusätzlich zu VGG\n\nTrainieren wir ein einfaches einschichtiges neuronales Netzwerk anhand der aus VGG extrahierten Funktionen.","metadata":{}},{"cell_type":"code","source":"model2 = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape = (x, y, z)),\n    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])\n\nmodel2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n\nhistory2 = model2.fit(train_features, train_labels, batch_size=128, epochs=15, validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T16:24:50.739274Z","iopub.execute_input":"2023-07-16T16:24:50.739713Z","iopub.status.idle":"2023-07-16T16:25:09.158149Z","shell.execute_reply.started":"2023-07-16T16:24:50.739681Z","shell.execute_reply":"2023-07-16T16:25:09.157161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracy_loss(history)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T16:25:14.834048Z","iopub.execute_input":"2023-07-16T16:25:14.834518Z","iopub.status.idle":"2023-07-16T16:25:15.275977Z","shell.execute_reply.started":"2023-07-16T16:25:14.834483Z","shell.execute_reply":"2023-07-16T16:25:15.274376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Wir sollten eine Genauigkeit von ungefähr 0,844 (+0,1 Genauigkeit) gegenüber dem einfachen ConvNet erreichen.","metadata":{}},{"cell_type":"code","source":"test_loss = model2.evaluate(test_features, test_labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T16:25:52.912634Z","iopub.execute_input":"2023-07-16T16:25:52.913075Z","iopub.status.idle":"2023-07-16T16:25:53.330149Z","shell.execute_reply.started":"2023-07-16T16:25:52.913041Z","shell.execute_reply":"2023-07-16T16:25:53.328674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble neuronaler Netze","metadata":{}},{"cell_type":"code","source":"np.random.seed(seed=1997)\n# Number of estimators\nn_estimators = 10\n# Proporition of samples to use to train each training\nmax_samples = 0.8\n\nmax_samples *= n_train\nmax_samples = int(max_samples)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T16:25:56.415161Z","iopub.execute_input":"2023-07-16T16:25:56.415614Z","iopub.status.idle":"2023-07-16T16:25:56.422386Z","shell.execute_reply.started":"2023-07-16T16:25:56.415579Z","shell.execute_reply":"2023-07-16T16:25:56.420695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wir definieren n_estimators Neuronale Netze.\n\nJedes neuronale Netzwerk wird anhand zufälliger Teilmengen des Trainingsdatensatzes trainiert. Jede Teilmenge enthält max_samples-Beispiele.","metadata":{}},{"cell_type":"code","source":"models = list()\nrandom = np.random.randint(50, 100, size = n_estimators)\n\nfor i in range(n_estimators):\n    \n    # Modell\n    model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape = (x, y, z)),\n                                # One layer with random size\n                                    tf.keras.layers.Dense(random[i], activation=tf.nn.relu),\n                                    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n                                ])\n    \n    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n    # Store-Modell\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T16:25:59.804281Z","iopub.execute_input":"2023-07-16T16:25:59.804716Z","iopub.status.idle":"2023-07-16T16:26:00.293007Z","shell.execute_reply.started":"2023-07-16T16:25:59.804665Z","shell.execute_reply":"2023-07-16T16:26:00.291866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"histories = []\n\nfor i in range(n_estimators):\n# Trainieren Sie jedes Modell anhand einer Tasche mit Trainingsdaten\n    \n    train_idx = np.random.choice(len(train_features), size = max_samples)\n    histories.append(models[i].fit(train_features[train_idx], train_labels[train_idx], batch_size=128, epochs=10, validation_split = 0.1))","metadata":{"execution":{"iopub.status.busy":"2023-07-16T16:26:03.632721Z","iopub.execute_input":"2023-07-16T16:26:03.633586Z","iopub.status.idle":"2023-07-16T16:28:06.143414Z","shell.execute_reply.started":"2023-07-16T16:26:03.633541Z","shell.execute_reply":"2023-07-16T16:28:06.142375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wir aggregieren die einzelnen Vorhersagen jedes Modells, um eine endgültige Vorhersage zu erstellen.","metadata":{}},{"cell_type":"code","source":"predictions = []\nfor i in range(n_estimators):\n    predictions.append(models[i].predict(test_features))\n    \npredictions = np.array(predictions)\npredictions = predictions.sum(axis = 0)\npred_labels = predictions.argmax(axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T16:28:06.145477Z","iopub.execute_input":"2023-07-16T16:28:06.145818Z","iopub.status.idle":"2023-07-16T16:28:10.948093Z","shell.execute_reply.started":"2023-07-16T16:28:06.145786Z","shell.execute_reply":"2023-07-16T16:28:10.946745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wir sollten unser Ergebnis verbessern, da wir eine geringere Varianz haben.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(\"Accuracy : {}\".format(accuracy_score(test_labels, pred_labels)))","metadata":{"execution":{"iopub.status.busy":"2023-07-16T16:28:42.516873Z","iopub.execute_input":"2023-07-16T16:28:42.517344Z","iopub.status.idle":"2023-07-16T16:28:42.526573Z","shell.execute_reply.started":"2023-07-16T16:28:42.517276Z","shell.execute_reply":"2023-07-16T16:28:42.524919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feinabstimmung von VGG ImageNet","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\n\nmodel = VGG16(weights='imagenet', include_top=False)\nmodel = Model(inputs=model.inputs, outputs=model.layers[-5].output)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T16:28:53.358474Z","iopub.execute_input":"2023-07-16T16:28:53.359364Z","iopub.status.idle":"2023-07-16T16:28:53.835500Z","shell.execute_reply.started":"2023-07-16T16:28:53.359310Z","shell.execute_reply":"2023-07-16T16:28:53.834556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features = model.predict(train_images)\ntest_features = model.predict(test_images)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T16:28:57.107229Z","iopub.execute_input":"2023-07-16T16:28:57.107670Z","iopub.status.idle":"2023-07-16T17:01:05.031991Z","shell.execute_reply.started":"2023-07-16T16:28:57.107635Z","shell.execute_reply":"2023-07-16T17:01:05.030406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Input, Dense, Conv2D, Activation , MaxPooling2D, Flatten\n\nmodel2 = VGG16(weights='imagenet', include_top=False)\n\ninput_shape = model2.layers[-4].get_input_shape_at(0) # get the input shape of desired layer\nlayer_input = Input(shape = (9, 9, 512)) # a new input tensor to be able to feed the desired layer\n# https://stackoverflow.com/questions/52800025/keras-give-input-to-intermediate-layer-and-get-final-output\n\nx = layer_input\nfor layer in model2.layers[-4::1]:\n    x = layer(x)\n    \nx = Conv2D(64, (3, 3), activation='relu')(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Flatten()(x)\nx = Dense(100,activation='relu')(x)\nx = Dense(6,activation='softmax')(x)\n\n# Erstellen Sie das Modell\nnew_model = Model(layer_input, x)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T17:01:13.927905Z","iopub.execute_input":"2023-07-16T17:01:13.928360Z","iopub.status.idle":"2023-07-16T17:01:14.470688Z","shell.execute_reply.started":"2023-07-16T17:01:13.928304Z","shell.execute_reply":"2023-07-16T17:01:14.469630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-16T17:01:22.299196Z","iopub.execute_input":"2023-07-16T17:01:22.299736Z","iopub.status.idle":"2023-07-16T17:01:22.316135Z","shell.execute_reply.started":"2023-07-16T17:01:22.299693Z","shell.execute_reply":"2023-07-16T17:01:22.314502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T17:01:25.923005Z","iopub.execute_input":"2023-07-16T17:01:25.924086Z","iopub.status.idle":"2023-07-16T17:01:25.968004Z","shell.execute_reply.started":"2023-07-16T17:01:25.924040Z","shell.execute_reply":"2023-07-16T17:01:25.966355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = new_model.fit(train_features, train_labels, batch_size=128, epochs=10, validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T17:06:53.090749Z","iopub.status.idle":"2023-07-16T17:06:53.091151Z","shell.execute_reply.started":"2023-07-16T17:06:53.090961Z","shell.execute_reply":"2023-07-16T17:06:53.090980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracy_loss(history)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T17:06:09.536182Z","iopub.execute_input":"2023-07-16T17:06:09.536625Z","iopub.status.idle":"2023-07-16T17:06:09.968065Z","shell.execute_reply.started":"2023-07-16T17:06:09.536592Z","shell.execute_reply":"2023-07-16T17:06:09.966470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\npredictions = new_model.predict(test_features)    \npred_labels = np.argmax(predictions, axis = 1)\nprint(\"Accuracy : {}\".format(accuracy_score(test_labels, pred_labels)))","metadata":{"execution":{"iopub.status.busy":"2023-07-16T17:06:13.424683Z","iopub.execute_input":"2023-07-16T17:06:13.425157Z","iopub.status.idle":"2023-07-16T17:06:41.952131Z","shell.execute_reply.started":"2023-07-16T17:06:13.425121Z","shell.execute_reply":"2023-07-16T17:06:41.951014Z"},"trusted":true},"execution_count":null,"outputs":[]}]}